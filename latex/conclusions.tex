\chapter{Conclusions}
\label{cha:conclusions}

The objective of this work was to develop a model capable of identifying and classifying the symptoms within a patient's statement.

In particular, as shown in chapter \ref{cha:results}, the Symptom Identifier can identify, using BERT, the 88.0 \% of the symptoms present in the sentences. However, in the meantime, it generates a considerable number of non-sense tokens for predictions which are detrimental because they will be inputs of the next component: the Symptom Classifier.

The Symptom Classifier takes as input the tokens for predictions originated by the previous component, of which 84.8 \% are correct (redundant and non-redundant), and outputs the CUI predictions based on them. Considering that the percentage of correct predictions is 48.0 \%, it is clear that the mapping is the main sub-component to perfect in order to improve the performance of the model.

However, the results are overall satisfactory because even using an extremely simple vector representation of symptoms (the mean of the embeddings of the words inside the concept name of the symptom), the model reaches an accuracy of $58.7 \%$ and a percentage of correct predictions of $48 \%$, doing 1.5 medium attempts for each real symptom in the sentences \footnote{Results achieved using BERT for QA, GloVe 200, minimum similarity level set at 0.8, Body Part Finder and ``pruning'' enabled}. The fact that these results depend strictly on the vector representations of symptoms shows that there is much scope for improvement. For example, a weakness of the vector representations of symptoms is that of being biased to the medical language (they were computed using a sentence which contain medical terms). 

\section{Further developments}
To improve the quality of the symptom representations can be worth to use, instead, the vectorization of symptom names expressed with the same language of a common patient. This could be useful in order to move closer linguistically and semantically to the problem that the patient wants to express.

A more radical modification of the last idea (but extremely difficult to realize) is that of creating a patient level classification of symptoms (independent from any language) and associating to each concept in this classification a list of expressions, which are the synonyms of the concept. For doing so it is necessary to collect a large quantity of patient's sentences, study how they express their problems and what is their common knowledge (and choose, of course, what it common knowledge and what is not).

% use contextual embeddings
Another possible future improvement could be the adoption of contextual embeddings. BERT embeddings are contextual; however, they did not outperform GloVe because they are not fine-tuned to a specific domain.

% Last improvement...
% use compositional syntax

    %%%%%%% USEFUL FOR FUTURE WORK
    % For example, there is no explicit concept for a "third degree burn of left index finger caused by hot water". However, using the compositional syntax it can be represented as:

    % \begin{verbatim}
    %    284196006 | burn of skin | :
    %    116676008 | associated morphology | = 80247002 | third degree burn injury |
    %  , 272741003 | laterality | = 7771000 | left |
    %  , 246075003 | causative agent | = 47448006 | hot water |
    %  , 363698007 | finding site | = 83738005 | index finger structure
    % \end{verbatim}
    %
    % BACK is both a preposition and a body part, then using contextual embeddings like bert finetuned or elmo embeddings could provide better results
    %%%%%%%